{
  "name": "Analytics Scrape Webhook",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "analytics/scrape",
        "responseMode": "responseNode",
        "options": {
          "allowedOrigins": "*"
        }
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [-400, 0],
      "id": "webhook-analytics-scrape",
      "name": "Webhook",
      "webhookId": "analytics-scrape"
    },
    {
      "parameters": {
        "jsCode": "const item = $input.first();\nconst { user_id, company_page_id } = item.json.body;\n\nconst errors = [];\n\nif (!user_id || typeof user_id !== 'string') {\n  errors.push('user_id is required and must be a string');\n}\n\nif (!company_page_id || typeof company_page_id !== 'string') {\n  errors.push('company_page_id is required and must be a string');\n}\n\nif (errors.length > 0) {\n  return [{\n    json: {\n      error: true,\n      errorType: 'VALIDATION_ERROR',\n      errorCode: 400,\n      errorMessage: errors.join(', ')\n    }\n  }];\n}\n\nreturn [{\n  json: {\n    ...item.json,\n    user_id,\n    company_page_id,\n    error: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-180, 0],
      "id": "validate-input",
      "name": "Validate Input"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "check-error",
              "leftValue": "={{ $json.error }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [40, 0],
      "id": "check-validation",
      "name": "Validation OK?"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseCode": "={{ $json.errorCode }}",
        "responseBody": "={{ JSON.stringify({ success: false, error: { code: $json.errorType, message: $json.errorMessage } }) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [280, -120],
      "id": "validation-error-response",
      "name": "Validation Error Response"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT id, page_url, page_name, platform, user_id FROM company_pages WHERE id = '{{ $json.company_page_id }}' AND user_id = '{{ $json.user_id }}' LIMIT 1",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [280, 120],
      "id": "verify-ownership",
      "name": "Verify Page Ownership",
      "credentials": {
        "postgres": {
          "id": "{{SUPABASE_POSTGRES_CREDENTIAL_ID}}",
          "name": "Supabase"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const items = $input.all();\n\nif (!items || items.length === 0 || !items[0].json.id) {\n  return [{\n    json: {\n      error: true,\n      errorType: 'NOT_FOUND',\n      errorCode: 404,\n      errorMessage: 'Company page not found or access denied'\n    }\n  }];\n}\n\nconst page = items[0].json;\n\nreturn [{\n  json: {\n    error: false,\n    page_id: page.id,\n    page_url: page.page_url,\n    page_name: page.page_name,\n    platform: page.platform,\n    user_id: page.user_id\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [500, 120],
      "id": "check-ownership-result",
      "name": "Check Ownership Result"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "check-page-error",
              "leftValue": "={{ $json.error }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [720, 120],
      "id": "page-found",
      "name": "Page Found?"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseCode": "={{ $json.errorCode }}",
        "responseBody": "={{ JSON.stringify({ success: false, error: { code: $json.errorType, message: $json.errorMessage } }) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [960, 0],
      "id": "not-found-response",
      "name": "Not Found Response"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO scrape_runs (company_page_id, user_id, status, started_at) VALUES ('{{ $json.page_id }}', '{{ $json.user_id }}', 'running', NOW()) RETURNING id",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [960, 240],
      "id": "create-scrape-run",
      "name": "Create Scrape Run",
      "credentials": {
        "postgres": {
          "id": "{{SUPABASE_POSTGRES_CREDENTIAL_ID}}",
          "name": "Supabase"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const runResult = $input.first();\nconst pageData = $('Check Ownership Result').first();\n\nreturn [{\n  json: {\n    scrape_run_id: runResult.json.id,\n    page_id: pageData.json.page_id,\n    page_url: pageData.json.page_url,\n    page_name: pageData.json.page_name,\n    platform: pageData.json.platform,\n    user_id: pageData.json.user_id\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1180, 240],
      "id": "merge-run-data",
      "name": "Merge Run Data"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.firecrawl.dev/v1/scrape",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ url: $json.page_url, formats: ['markdown'], waitFor: 3000 }) }}",
        "options": {
          "timeout": 60000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1400, 240],
      "id": "firecrawl-scrape",
      "name": "Firecrawl Scrape",
      "credentials": {
        "httpHeaderAuth": {
          "id": "{{FIRECRAWL_CREDENTIAL_ID}}",
          "name": "Firecrawl API"
        }
      },
      "retryOnFail": true,
      "maxTries": 2,
      "waitBetweenTries": 3000,
      "continueOnFail": true
    },
    {
      "parameters": {
        "jsCode": "const firecrawlResponse = $input.first();\nconst prevData = $('Merge Run Data').first();\n\n// Check if Firecrawl returned an error\nif (firecrawlResponse.json.error || !firecrawlResponse.json.data) {\n  const errorMsg = firecrawlResponse.json.error?.message || firecrawlResponse.json.message || 'Firecrawl scrape failed';\n  return [{\n    json: {\n      error: true,\n      errorMessage: errorMsg,\n      scrape_run_id: prevData.json.scrape_run_id,\n      page_id: prevData.json.page_id,\n      user_id: prevData.json.user_id,\n      platform: prevData.json.platform,\n      posts: []\n    }\n  }];\n}\n\nconst markdown = firecrawlResponse.json.data.markdown || '';\nconst posts = [];\n\n// Split by common LinkedIn post delimiters\n// LinkedIn company pages typically show posts separated by horizontal rules or distinct sections\nconst postSections = markdown.split(/(?=#{1,3}\\s)|(?=---)|(?=\\*\\*\\*)|(?=\\n\\n(?:[A-Z][^\\n]{10,})\\n)/).filter(s => s.trim().length > 50);\n\nfor (let i = 0; i < postSections.length; i++) {\n  const section = postSections[i].trim();\n  \n  // Skip navigation/header sections\n  if (section.match(/^(Home|About|Posts|Jobs|People|Events|Videos|Sign|Log)/i)) continue;\n  if (section.length < 80) continue;\n  \n  // Extract post content - take the main text block\n  let content = section\n    .replace(/^#{1,3}\\s+.*\\n/, '') // Remove headings\n    .replace(/!\\[.*?\\]\\(.*?\\)/g, '') // Remove images\n    .replace(/\\[([^\\]]+)\\]\\(([^)]+)\\)/g, '$1') // Convert links to text\n    .replace(/\\*\\*/g, '') // Remove bold markers\n    .replace(/\\n{3,}/g, '\\n\\n') // Normalize newlines\n    .trim();\n  \n  if (content.length < 50) continue;\n  \n  // Try to extract engagement metrics from the section\n  const reactionsMatch = section.match(/(\\d[\\d,.]*)\\s*(?:reactions?|likes?)/i);\n  const commentsMatch = section.match(/(\\d[\\d,.]*)\\s*comments?/i);\n  const sharesMatch = section.match(/(\\d[\\d,.]*)\\s*(?:shares?|reposts?)/i);\n  \n  const parseCount = (match) => {\n    if (!match) return 0;\n    return parseInt(match[1].replace(/[,.]/g, ''), 10) || 0;\n  };\n  \n  // Try to extract post URL\n  const urlMatch = section.match(/\\(https:\\/\\/www\\.linkedin\\.com\\/feed\\/update\\/[^)]+\\)/);\n  const postUrl = urlMatch ? urlMatch[0].slice(1, -1) : null;\n  \n  // Try to extract date\n  const dateMatch = section.match(/(\\d{1,2}[dhmw]|\\d{1,2}\\s+(?:hours?|days?|weeks?|months?)\\s+ago|\\w+\\s+\\d{1,2},?\\s+\\d{4})/i);\n  let postedAt = null;\n  if (dateMatch) {\n    const dateStr = dateMatch[1];\n    // Try to parse relative dates\n    const now = new Date();\n    const daysMatch = dateStr.match(/(\\d+)d/);\n    const weeksMatch = dateStr.match(/(\\d+)w/);\n    const monthsMatch = dateStr.match(/(\\d+)mo/);\n    if (daysMatch) {\n      now.setDate(now.getDate() - parseInt(daysMatch[1]));\n      postedAt = now.toISOString();\n    } else if (weeksMatch) {\n      now.setDate(now.getDate() - parseInt(weeksMatch[1]) * 7);\n      postedAt = now.toISOString();\n    } else if (monthsMatch) {\n      now.setMonth(now.getMonth() - parseInt(monthsMatch[1]));\n      postedAt = now.toISOString();\n    } else {\n      try { postedAt = new Date(dateStr).toISOString(); } catch(e) {}\n    }\n  }\n  \n  // Detect media type\n  let mediaType = 'text';\n  if (section.match(/!\\[.*?\\]\\(.*?\\)/)) mediaType = 'image';\n  if (section.match(/video|watch|play/i)) mediaType = 'video';\n  if (section.match(/carousel|slides?|swipe/i)) mediaType = 'carousel';\n  \n  // Generate a deterministic external_id from content hash\n  const hashSource = content.substring(0, 200);\n  let hash = 0;\n  for (let j = 0; j < hashSource.length; j++) {\n    const char = hashSource.charCodeAt(j);\n    hash = ((hash << 5) - hash) + char;\n    hash = hash & hash; // Convert to 32bit integer\n  }\n  const externalId = 'li_' + Math.abs(hash).toString(36);\n  \n  // Clean up content: remove engagement metrics lines at the end\n  content = content\n    .replace(/\\d[\\d,.]*\\s*(?:reactions?|likes?|comments?|shares?|reposts?).*$/gim, '')\n    .replace(/Like\\s*Comment\\s*Share.*/gi, '')\n    .replace(/\\n\\s*\\n\\s*\\n/g, '\\n\\n')\n    .trim();\n  \n  if (content.length < 50) continue;\n  \n  posts.push({\n    external_id: externalId,\n    content: content.substring(0, 5000),\n    post_url: postUrl,\n    posted_at: postedAt,\n    reactions_count: parseCount(reactionsMatch),\n    comments_count: parseCount(commentsMatch),\n    shares_count: parseCount(sharesMatch),\n    media_type: mediaType\n  });\n}\n\nreturn [{\n  json: {\n    error: false,\n    scrape_run_id: prevData.json.scrape_run_id,\n    page_id: prevData.json.page_id,\n    user_id: prevData.json.user_id,\n    platform: prevData.json.platform,\n    posts: posts,\n    posts_found: posts.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1620, 240],
      "id": "parse-firecrawl-response",
      "name": "Parse Firecrawl Response"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "check-scrape-error",
              "leftValue": "={{ $json.error }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1840, 240],
      "id": "scrape-ok",
      "name": "Scrape OK?"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE scrape_runs SET status = 'error', error_message = '{{ $json.errorMessage }}', completed_at = NOW() WHERE id = '{{ $json.scrape_run_id }}'",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2080, 120],
      "id": "update-run-error",
      "name": "Update Run Error",
      "credentials": {
        "postgres": {
          "id": "{{SUPABASE_POSTGRES_CREDENTIAL_ID}}",
          "name": "Supabase"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseCode": 500,
        "responseBody": "={{ JSON.stringify({ success: false, error: { code: 'SCRAPE_ERROR', message: $('Parse Firecrawl Response').first().json.errorMessage } }) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [2300, 120],
      "id": "scrape-error-response",
      "name": "Scrape Error Response"
    },
    {
      "parameters": {
        "jsCode": "const data = $input.first().json;\nconst posts = data.posts || [];\n\nif (posts.length === 0) {\n  return [{\n    json: {\n      ...data,\n      posts_new: 0,\n      posts_updated: 0,\n      upsert_complete: true\n    }\n  }];\n}\n\n// Build a single UPSERT query for all posts\nconst values = posts.map(p => {\n  const esc = (v) => v === null || v === undefined ? 'NULL' : `'${String(v).replace(/'/g, \"''\")}'`;\n  return `(${esc(data.page_id)}, ${esc(data.user_id)}, ${esc(data.platform)}, ${esc(p.external_id)}, ${esc(p.content)}, ${esc(p.post_url)}, ${p.posted_at ? esc(p.posted_at) : 'NULL'}, ${p.reactions_count || 0}, ${p.comments_count || 0}, ${p.shares_count || 0}, ${esc(p.media_type)})`;\n}).join(',\\n');\n\nconst query = `\nWITH upserted AS (\n  INSERT INTO scraped_posts (company_page_id, user_id, platform, external_id, content, post_url, posted_at, reactions_count, comments_count, shares_count, media_type)\n  VALUES ${values}\n  ON CONFLICT (company_page_id, external_id) DO UPDATE SET\n    content = EXCLUDED.content,\n    post_url = EXCLUDED.post_url,\n    posted_at = EXCLUDED.posted_at,\n    reactions_count = EXCLUDED.reactions_count,\n    comments_count = EXCLUDED.comments_count,\n    shares_count = EXCLUDED.shares_count,\n    media_type = EXCLUDED.media_type,\n    updated_at = NOW()\n  RETURNING id, (xmax = 0) AS is_new\n)\nSELECT\n  COUNT(*) AS total,\n  COUNT(*) FILTER (WHERE is_new) AS new_count,\n  COUNT(*) FILTER (WHERE NOT is_new) AS updated_count\nFROM upserted;\n`;\n\nreturn [{\n  json: {\n    ...data,\n    upsert_query: query\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2080, 360],
      "id": "build-upsert-query",
      "name": "Build Upsert Query"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "check-has-posts",
              "leftValue": "={{ $json.upsert_complete }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [2300, 360],
      "id": "has-posts",
      "name": "Has Posts?"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "={{ $('Build Upsert Query').first().json.upsert_query }}",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2520, 480],
      "id": "upsert-posts",
      "name": "Upsert Posts",
      "credentials": {
        "postgres": {
          "id": "{{SUPABASE_POSTGRES_CREDENTIAL_ID}}",
          "name": "Supabase"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "jsCode": "const upsertResult = $input.first();\nconst prevData = $('Build Upsert Query').first().json;\n\n// Check if the upsert had an error\nif (upsertResult.json.error) {\n  return [{\n    json: {\n      scrape_run_id: prevData.scrape_run_id,\n      page_id: prevData.page_id,\n      user_id: prevData.user_id,\n      posts_found: prevData.posts_found || 0,\n      posts_new: 0,\n      posts_updated: 0,\n      db_error: true,\n      errorMessage: upsertResult.json.error.message || 'Upsert failed'\n    }\n  }];\n}\n\nreturn [{\n  json: {\n    scrape_run_id: prevData.scrape_run_id,\n    page_id: prevData.page_id,\n    user_id: prevData.user_id,\n    posts_found: prevData.posts_found || 0,\n    posts_new: parseInt(upsertResult.json.new_count) || 0,\n    posts_updated: parseInt(upsertResult.json.updated_count) || 0,\n    db_error: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2740, 480],
      "id": "process-upsert-result",
      "name": "Process Upsert Result"
    },
    {
      "parameters": {
        "jsCode": "// No posts path - build result directly\nconst prevData = $input.first().json;\n\nreturn [{\n  json: {\n    scrape_run_id: prevData.scrape_run_id,\n    page_id: prevData.page_id,\n    user_id: prevData.user_id,\n    posts_found: 0,\n    posts_new: 0,\n    posts_updated: 0,\n    db_error: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2520, 240],
      "id": "no-posts-result",
      "name": "No Posts Result"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE scrape_runs SET status = CASE WHEN {{ $json.db_error }} THEN 'error' ELSE 'success' END, posts_found = {{ $json.posts_found }}, posts_new = {{ $json.posts_new }}, posts_updated = {{ $json.posts_updated }}, error_message = CASE WHEN {{ $json.db_error }} THEN '{{ $json.errorMessage }}' ELSE NULL END, completed_at = NOW() WHERE id = '{{ $json.scrape_run_id }}'",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2960, 360],
      "id": "update-run-success",
      "name": "Update Scrape Run",
      "credentials": {
        "postgres": {
          "id": "{{SUPABASE_POSTGRES_CREDENTIAL_ID}}",
          "name": "Supabase"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE company_pages SET last_scraped_at = NOW() WHERE id = '{{ $('Process Upsert Result').first().json.page_id || $('No Posts Result').first().json.page_id }}'",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [3180, 360],
      "id": "update-last-scraped",
      "name": "Update Last Scraped",
      "credentials": {
        "postgres": {
          "id": "{{SUPABASE_POSTGRES_CREDENTIAL_ID}}",
          "name": "Supabase"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseCode": 200,
        "responseBody": "={{ JSON.stringify({ success: true, data: { status: $('Process Upsert Result').first()?.json.db_error ? 'partial' : 'success', posts_found: $('Process Upsert Result').first()?.json.posts_found || $('No Posts Result').first()?.json.posts_found || 0, posts_new: $('Process Upsert Result').first()?.json.posts_new || 0, posts_updated: $('Process Upsert Result').first()?.json.posts_updated || 0 } }) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [3400, 360],
      "id": "success-response",
      "name": "Success Response"
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Validate Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Input": {
      "main": [
        [
          {
            "node": "Validation OK?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validation OK?": {
      "main": [
        [
          {
            "node": "Validation Error Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Verify Page Ownership",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Verify Page Ownership": {
      "main": [
        [
          {
            "node": "Check Ownership Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Ownership Result": {
      "main": [
        [
          {
            "node": "Page Found?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Page Found?": {
      "main": [
        [
          {
            "node": "Not Found Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Create Scrape Run",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Scrape Run": {
      "main": [
        [
          {
            "node": "Merge Run Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Run Data": {
      "main": [
        [
          {
            "node": "Firecrawl Scrape",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Firecrawl Scrape": {
      "main": [
        [
          {
            "node": "Parse Firecrawl Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Firecrawl Response": {
      "main": [
        [
          {
            "node": "Scrape OK?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Scrape OK?": {
      "main": [
        [
          {
            "node": "Update Run Error",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Build Upsert Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Run Error": {
      "main": [
        [
          {
            "node": "Scrape Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Upsert Query": {
      "main": [
        [
          {
            "node": "Has Posts?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Posts?": {
      "main": [
        [
          {
            "node": "No Posts Result",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Upsert Posts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upsert Posts": {
      "main": [
        [
          {
            "node": "Process Upsert Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Upsert Result": {
      "main": [
        [
          {
            "node": "Update Scrape Run",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "No Posts Result": {
      "main": [
        [
          {
            "node": "Update Scrape Run",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Scrape Run": {
      "main": [
        [
          {
            "node": "Update Last Scraped",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Last Scraped": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "availableInMCP": false
  },
  "versionId": "",
  "meta": {
    "instanceId": ""
  },
  "id": "",
  "tags": []
}